# BLRQ-BV
（1）For English, we adopt the bert-base-uncased model. For Chinese, we use the bert-base-chinese model. 
（2）Meanwhile, different tokenizers are employed for the BiLSTM model in Chinese and English scenarios respectively.
