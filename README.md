# BLRQ-BV
For English, we adopt the bert-base-uncased model. For Chinese, we use the bert-base-chinese model. 
Meanwhile, different tokenizers are employed for the BiLSTM model in Chinese and English scenarios respectively.
